{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Dataset\n",
    "Please note that this is the original dataset with additional information and proper attribution. There is at least one other version of this dataset on Kaggle that was uploaded without permission. Please be fair and attribute the original author.\n",
    "This synthetic dataset is modeled after an existing milling machine and consists of 10 000 data points from a stored as rows with 14 features in columns\n",
    "\n",
    "UID: unique identifier ranging from 1 to 10000\n",
    "\n",
    "product ID: consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial number\n",
    "\n",
    "type: just the product type L, M or H from column 2\n",
    "\n",
    "air temperature [K]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K\n",
    "process temperature [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.\n",
    "\n",
    "rotational speed [rpm]: calculated from a power of 2860 W, overlaid with a normally distributed noise\n",
    "\n",
    "torque [Nm]: torque values are normally distributed around 40 Nm with a SD = 10 Nm and no negative values.\n",
    "\n",
    "tool wear [min]: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process.\n",
    "\n",
    "a 'machine failure' label that indicates, whether the machine has failed in this particular datapoint for any of the following failure modes are true.\n",
    "### The machine failure consists of five independent failure modes\n",
    "\n",
    "###### 1) tool wear failure (TWF): the tool will be replaced of fail at a randomly selected tool wear time between 200 - 240 mins (120 times in our dataset). At this point in time, the tool is replaced 69 times, and fails 51 times (randomly assigned).\n",
    "\n",
    "###### 2) heat dissipation failure (HDF): heat dissipation causes a process failure, if the difference between air- and process temperature is below 8.6 K and the tools rotational speed is below 1380 rpm. This is the case for 115 data points.\n",
    "\n",
    "###### 3) power failure (PWF): the product of torque and rotational speed (in rad/s) equals the power required for the process. If this power is below 3500 W or above 9000 W, the process fails, which is the case 95 times in our dataset.\n",
    "\n",
    "###### 4) overstrain failure (OSF): if the product of tool wear and torque exceeds 11,000 minNm for the L product variant (12,000 M, 13,000 H), the process fails due to overstrain. This is true for 98 datapoints.\n",
    "\n",
    "###### 5) random failures (RNF): each process has a chance of 0,1 % to fail regardless of its process parameters. This is the case for only 5 datapoints, less than could be expected for 10,000 datapoints in our dataset.\n",
    "\n",
    "#####  If at least one of the above failure modes is true, the process fails and the 'machine failure' label is set to 1. It is therefore not transparent to the machine learning method, which of the failure modes has caused the process to fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"ai4i2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop UDI and Product ID columns because all values in them are unique\n",
    "df.drop(columns=['UDI','Product ID'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This visualization shows this unbalanced data\n",
    "\n",
    "failure_columns = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a countplot for each failure type\n",
    "for i, col in enumerate(failure_columns):\n",
    "    plt.subplot(2, 3, i+1)  # 2 rows, 3 columns grid\n",
    "    sns.countplot(x=col, data=df)\n",
    "    plt.title(f'{col} Distribution')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(ticks=[0, 1], labels=['No Failure', 'Failure'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['No failure']=df['Machine failure']==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['No failure']=df['No failure'].replace({True:1,False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=df[['TWF','HDF','PWF','OSF','RNF','No failure']]\n",
    "df['merged_target'] = targets.idxmax(axis=1)\n",
    "df['merged_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb=LabelEncoder()\n",
    "lb.fit(df['merged_target'])\n",
    "\n",
    "print(lb.classes_)      # Shows original categories\n",
    "print(lb.transform(lb.classes_))  # Shows corresponding encoded values\n",
    "df['merged_target']=lb.transform(df['merged_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb=LabelEncoder()\n",
    "lb.fit(df['Type'])\n",
    "print(lb.classes_)      # Shows original categories\n",
    "print(lb.transform(lb.classes_))  # Shows corresponding encoded values\n",
    "df['Type']=lb.transform(df['Type'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['TWF','HDF','PWF','OSF','RNF','Machine failure','No failure'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=df['merged_target']\n",
    "x=df.drop(columns=['merged_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm=SMOTE(random_state=42)\n",
    "X,target_res=sm.fit_resample(x,target)\n",
    "X=pd.DataFrame(X)\n",
    "target_res=pd.DataFrame(target_res)\n",
    "target_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_res=target_res.replace({0:'HDF', 1:'No failure', 2:'OSF', 3:'PWF', 4:'RNF', 5:'TWF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df= pd.concat([X, target_res], axis=1)\n",
    "df['Type']=df['Type'].replace({0:'H',1:'L',2:'M'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "onehotencoder=OneHotEncoder()\n",
    "X=onehotencoder.fit_transform(df[['merged_target']]).toarray()\n",
    "for index , col in enumerate(onehotencoder.categories_[0]) :\n",
    "    df[col]=X[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['merged_target'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_columns = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a countplot for each failure type\n",
    "for i, col in enumerate(failure_columns):\n",
    "    plt.subplot(2, 3, i+1)  # 2 rows, 3 columns grid\n",
    "    sns.countplot(x=col, data=df)\n",
    "    plt.title(f'{col} Distribution')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(ticks=[0, 1], labels=['No Failure', 'Failure'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_columns = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a countplot for each failure type\n",
    "for i, col in enumerate(failure_columns):\n",
    "    plt.subplot(2, 3, i+1)  # 2 rows, 3 columns grid\n",
    "    sns.scatterplot(data=df, \n",
    "               x='Torque [Nm]', \n",
    "               y='Rotational speed [rpm]', \n",
    "               hue=col,\n",
    "               palette='viridis',\n",
    "               alpha=0.7)\n",
    "    plt.title(f'{col} by Torque and RPM')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define failure types\n",
    "failure_types = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "\n",
    "# Plot KDE for each failure type\n",
    "for failure, color in zip(failure_types, colors):\n",
    "    failure_tool_wear = df[df[failure] == 1]['Tool wear [min]']\n",
    "    sns.kdeplot(failure_tool_wear, \n",
    "                label=f'{failure} Failure', \n",
    "                fill=True, \n",
    "                color=color,\n",
    "                alpha=0.5)\n",
    "    \n",
    "    # Add mean line\n",
    "    plt.axvline(failure_tool_wear.mean(), \n",
    "                color=color, \n",
    "                linestyle='--', \n",
    "                linewidth=2,\n",
    "                label=f'{failure} Mean')\n",
    "\n",
    "plt.xlabel('Tool wear [min]')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Tool Wear Distribution by Failure Type')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define failure types\n",
    "failure_types = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "\n",
    "# Plot KDE for each failure type\n",
    "for failure, color in zip(failure_types, colors):\n",
    "    failure_tool_wear = df[df[failure] == 1]['Torque [Nm]']\n",
    "    sns.kdeplot(failure_tool_wear, \n",
    "                label=f'{failure} Failure', \n",
    "                fill=True, \n",
    "                color=color,\n",
    "                alpha=0.5)\n",
    "    \n",
    "    # Add mean line\n",
    "    plt.axvline(failure_tool_wear.mean(), \n",
    "                color=color, \n",
    "                linestyle='--', \n",
    "                linewidth=2,\n",
    "                label=f'{failure} Mean')\n",
    "\n",
    "plt.xlabel('Torque [Nm]')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Torque Distribution by Failure Type')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define failure types\n",
    "failure_types = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "\n",
    "# Plot KDE for each failure type\n",
    "for failure, color in zip(failure_types, colors):\n",
    "    failure_tool_wear = df[df[failure] == 1]['Rotational speed [rpm]']\n",
    "    sns.kdeplot(failure_tool_wear, \n",
    "                label=f'{failure} Failure', \n",
    "                fill=True, \n",
    "                color=color,\n",
    "                alpha=0.5)\n",
    "    \n",
    "    # Add mean line\n",
    "    plt.axvline(failure_tool_wear.mean(), \n",
    "                color=color, \n",
    "                linestyle='--', \n",
    "                linewidth=2,\n",
    "                label=f'{failure} Mean')\n",
    "\n",
    "plt.xlabel('Rotational speed [rpm]')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Rotational speed Distribution by Failure Type')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define failure types\n",
    "failure_types = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "\n",
    "# Plot KDE for each failure type\n",
    "for failure, color in zip(failure_types, colors):\n",
    "    failure_tool_wear = df[df[failure] == 1]['Process temperature [K]']\n",
    "    sns.kdeplot(failure_tool_wear, \n",
    "                label=f'{failure} Failure', \n",
    "                fill=True, \n",
    "                color=color,\n",
    "                alpha=0.5)\n",
    "    \n",
    "    # Add mean line\n",
    "    plt.axvline(failure_tool_wear.mean(), \n",
    "                color=color, \n",
    "                linestyle='--', \n",
    "                linewidth=2,\n",
    "                label=f'{failure} Mean')\n",
    "\n",
    "plt.xlabel('Process temperature [K]')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Process temperature Distribution by Failure Type')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define failure types\n",
    "failure_types = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "\n",
    "# Plot KDE for each failure type\n",
    "for failure, color in zip(failure_types, colors):\n",
    "    failure_tool_wear = df[df[failure] == 1]['Air temperature [K]']\n",
    "    sns.kdeplot(failure_tool_wear, \n",
    "                label=f'{failure} Failure', \n",
    "                fill=True, \n",
    "                color=color,\n",
    "                alpha=0.5)\n",
    "    \n",
    "    # Add mean line\n",
    "    plt.axvline(failure_tool_wear.mean(), \n",
    "                color=color, \n",
    "                linestyle='--', \n",
    "                linewidth=2,\n",
    "                label=f'{failure} Mean')\n",
    "\n",
    "plt.xlabel('Air temperature [K]')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Air temperature Distribution by Failure Type')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_columns = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a countplot for each failure type\n",
    "for i, col in enumerate(failure_columns):\n",
    "    plt.subplot(2, 3, i+1)  # 2 rows, 3 columns grid\n",
    "    sns.countplot(data=df, x='Type', hue=col)\n",
    "    plt.title(f'{col} by type')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=df['Torque [Nm]'])\n",
    "plt.title(\"Box Plot - Detecting Outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=df['Rotational speed [rpm]'])\n",
    "plt.title(\"Box Plot - Detecting Outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=df['Process temperature [K]'])\n",
    "plt.title(\"Box Plot - Detecting Outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Torque [Nm]'], kde=True, stat=\"density\", bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Rotational speed [rpm]'], kde=True, stat=\"density\", bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Process temperature [K]'], kde=True, stat=\"density\", bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Tool wear [min]'], kde=True, stat=\"density\", bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    lb=LabelEncoder()\n",
    "    df[col]=lb.fit_transform(df[col])\n",
    "    filename = f\"{col}_label_encoder.pkl\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(lb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df.drop(columns=['TWF','HDF','PWF','OSF','RNF','No failure'])\n",
    "y=df[['TWF','HDF','PWF','OSF','RNF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "for col in features.columns:\n",
    "    my_scaler=MinMaxScaler()\n",
    "    features[col]=my_scaler.fit_transform(features[[col]])\n",
    "    filename = f\"{col}_MinMaxScaler.pkl\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(my_scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def multilabel_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    \"\"\"Manual implementation of multilabel stratified split\"\"\"\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Get unique label combinations and their counts\n",
    "    label_combos = y.astype(str).apply('_'.join, axis=1)\n",
    "    combo_counts = label_combos.value_counts()\n",
    "    \n",
    "    # Initialize indices\n",
    "    train_idx, test_idx = [], []\n",
    "    \n",
    "    # Stratify each label combination separately\n",
    "    for combo in combo_counts.index:\n",
    "        combo_indices = np.where(label_combos == combo)[0]\n",
    "        np.random.shuffle(combo_indices)\n",
    "        \n",
    "        split_point = int(len(combo_indices) * (1 - test_size))\n",
    "        train_idx.extend(combo_indices[:split_point])\n",
    "        test_idx.extend(combo_indices[split_point:])\n",
    "    \n",
    "    return X.iloc[train_idx], X.iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "# Usage\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(\n",
    "    features, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Evaluation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,f1_score,recall_score,accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Overall_Accuracy=[]\n",
    "models={\n",
    "    \"LogisticRegression\":MultiOutputClassifier(LogisticRegression(random_state=1,class_weight='balanced')),\n",
    "    \"SVM\": MultiOutputClassifier(SVC()),\n",
    "   \"KNeighborsClassifier\":MultiOutputClassifier(KNeighborsClassifier()),\n",
    "   \"GaussianNB\":MultiOutputClassifier(GaussianNB()),\n",
    "   \"DecisionTreeClassifier\":MultiOutputClassifier(DecisionTreeClassifier(random_state=1,criterion = 'entropy',max_depth=28,class_weight='balanced')), #{\"gini\", \"entropy\", \"log_loss\"}),\n",
    "    \"RandomForestClassifier\":MultiOutputClassifier(RandomForestClassifier(random_state=1,n_estimators= 20 , criterion = 'entropy',max_depth=50,class_weight='balanced'))\n",
    "   \n",
    "}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    Overall_Accuracy.append(accuracy_score(y_test, y_pred))\n",
    "performance=pd.DataFrame([Overall_Accuracy],columns=models.keys(),index=['Overall_Accuracy']).T\n",
    "\n",
    "performance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "param_grid = {\n",
    "    \"n_estimators\":range(18,24,2),\n",
    "    'max_depth': range(45,55, 2),\n",
    "    #'min_samples_leaf': range(1, 10, 1),\n",
    "    #'min_samples_split': range(2, 10, 1),\n",
    "    'criterion': [\"entropy\", \"gini\"],\n",
    "    'class_weight':['balanced']\n",
    "}\n",
    "model = MultiOutputClassifier(rf)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=4)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"best accuracy using GridSearchCV\", grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "rf = grid_search.best_estimator_\n",
    "\n",
    "# Multi-output wrapper\n",
    "model = MultiOutputClassifier(rf)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = np.mean([estimator.feature_importances_ for estimator in model.estimators_], axis=0)\n",
    "feature_names = features.columns\n",
    "\n",
    "# Create a DataFrame\n",
    "feature_imp_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_imp_df, palette='viridis')\n",
    "plt.title('Average Feature Importance Across All Outputs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, recall_score, accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#'Process temperature [K]',\n",
    "features = ['Air temperature [K]',\n",
    "            'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "targets = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "\n",
    "# 1. Classification report and accuracy for each failure type\n",
    "for i, target in enumerate(targets):\n",
    "    print(f\"\\nEvaluation for {target}:\")\n",
    "    print(classification_report(y_test[target], y_pred[:, i]))\n",
    "    print(f\"Accuracy: {accuracy_score(y_test[target], y_pred[:, i]):.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test[target], y_pred[:, i])\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Negative', 'Positive'], \n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    plt.title(f'Confusion Matrix for {target}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "# 2. ROC curves for all failure types\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    fpr, tpr, _ = roc_curve(y_test[target], y_pred[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{target} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Each Failure Type')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Combined evaluation\n",
    "print(\"\\nOverall Accuracy:\")\n",
    "print(f\"{accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"RandomForestClassifier.pkl\"\n",
    "with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<div style=\"text-align: center; font-size: 48px; color:white; font-weight: bold;\">\n",
    "    THANK YOU!\n",
    "</div>\n",
    "<br><br>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2609801,
     "sourceId": 4458097,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
